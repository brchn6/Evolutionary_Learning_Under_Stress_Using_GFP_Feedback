# ğŸ§¬ Evolutionary Learning Laboratory (Moran Process)

**Interactive simulation of temperature-feedbackâ€“driven adaptation in synthetic yeast populations**

This app models evolutionary â€œlearningâ€ via a **strict Moran (birthâ€“death)** process where each time step performs **exactly one birth and one death**, keeping population size constant. A feedback controller cools the environment as the populationâ€™s mean GFP rises. **Control wells are hard-coded to 30Â°C and 39Â°C** for the entire run.

---

## ğŸš€ Quick Start

### Requirements

* Python 3.9â€“3.11
* macOS/Linux/Windows

### Install & Run

```bash
# Clone
git clone <your-repo>
cd evolutionary-learning

# Install dependencies
pip install -r requirements.txt

# Launch the Streamlit app
streamlit run app.py
```

Then open your browser at `http://localhost:8501`, keep defaults, click **â€œğŸš€ Run Evolution Experimentâ€**, and explore the dashboard.

---

## ğŸ“ Project Structure

```
evolutionary-learning/
â”œâ”€ app.py                   # Streamlit UI
â”œâ”€ src/
â”‚  â””â”€ main.py               # Core engine: strict Moran BD, models, utilities
â”œâ”€ requirements.txt         # Dependencies
â””â”€ README.md                # This guide
```

> The UI imports the engine via `from src.main import ...`.

---

## ğŸ§  Whatâ€™s New / Key Behavior

* **Strict Moran updates:** every step = **1 fitness-proportional birth + 1 uniform death**.
* **Controls locked:** 30.0Â°C and 39.0Â°C **forever** (no feedback, no smoothing, no startup logic).
* **Driver only uses feedback + inertia:** optional first-minute hold and smoothing.
* **Exports include control temperatures** for easy verification.
* **Generation-time landscape** plot derived from the exact model equations.
* **Metrics burn-in** to ignore early transients.

---

## ğŸ–¥ï¸ App Features

* **Driver, Passives, Controls:**

  * **Driver**: experiences temperature set by GFPâ†’Temp feedback.
  * **Passives**: experience the **same temperature** as the driver but **do not influence it**.
  * **Controls**: **30Â°C** and **39Â°C** constant every step.
* **Modes:** `continuous` or `binary` GFP expression.
* **Plots:** Temperature & GFP time series, feedback curve vs. trajectory, learning progress, and a generation-time heatmap.
* **Downloads:** CSV time series, JSON parameters + metrics, and raw JSON.

---

## ğŸ›ï¸ Parameters (UI ranges & effects)

### ğŸ”¬ Core Experimental Setup

| UI Control                  | Range (default)                        | Meaning                                     |
| --------------------------- | -------------------------------------- | ------------------------------------------- |
| **GFP Expression Mode**     | `continuous` / `binary` (`continuous`) | Trait model                                 |
| **Simulation Time (min)**   | 200â€“3000 (**1000**)                    | Total minutes simulated                     |
| **Time Step (min/event)**   | 1â€“10 (**1**)                           | Minutes per Moran event (1 birth + 1 death) |
| **Population Size (cells)** | 50â€“800 (**200**)                       | Constant size via Moran BD                  |
| **Number of Passive Wells** | 1â€“8 (**3**)                            | Passive replicates                          |

### ğŸŒ¡ï¸ Temperature Feedback (Driver only)

| UI Control               | Range (default)                                       | Notes                                     |
| ------------------------ | ----------------------------------------------------- | ----------------------------------------- |
| **Feedback Function**    | `linear`, `sigmoid`, `step`, `exponential` (`linear`) | GFPâ†’Temp mapping                          |
| **Feedback Sensitivity** | 0.2â€“4.0 (**1.0**)                                     | Higher â†’ stronger cooling response        |
| **Range**                | **30Â°C â†” 39Â°C** (fixed)                               | Driver operates strictly within this span |

**Feedback function (engine):**

```
temperature = max_temp - cooling_factor * (max_temp - base_temp)
```

with different definitions of `cooling_factor` per mode (linear/sigmoid/step/exponential). Values are clipped to \[30, 39] Â°C.

### ğŸ§¬ Evolution & Fitness

> Internally maps to `GFPParams` (`inherit_sd`, `switch_prob_base`, `cost_strength`, `cost_exponent`)

| UI Control                         | Range (default)       | Effect                                          |
| ---------------------------------- | --------------------- | ----------------------------------------------- |
| **Inheritance Noise (continuous)** | 1.0â€“20.0 (**5.0**)    | Daughter GFP = mother Â± noise (continuous mode) |
| **Stress-Induced Switching Rate**  | 0.001â€“0.08 (**0.01**) | Per-step, scaled up by heat                     |
| **GFP Metabolic Cost**             | 0.0â€“1.2 (**0.3**)     | Higher GFP â†’ slower division                    |
| **Cost Function Curvature**        | 0.5â€“3.0 (**1.5**)     | Nonlinearity of the cost                        |

**Generation time model (per cell):**

* Base vs. temperature:
  `base_time = 60 + 120 * ((Tâˆ’30)/9)^2` (clipped to 30â€“39Â°C â†’ \[0,1])
* Cost multiplier:

  * **Continuous:** `1 + cost_strength * (gfp/100)^cost_exponent`
  * **Binary:** `1.3` if GFP>50 else `1.0`
* **Generation time = base\_time Ã— cost\_multiplier**
* **Fitness âˆ 1/generation\_time**

### ğŸ§Š Smoothing & Metrics (Driver)

| UI Control               | Range (default)          | Notes                                            |
| ------------------------ | ------------------------ | ------------------------------------------------ |
| **Temperature Inertia**  | 0.05â€“1.0 (**0.25**)      | Smoother changes for lower values                |
| **Start at Max Temp**    | toggle (**True**)        | First step holds 39Â°C; otherwise start at target |
| **Metric Burn-in (min)** | 0â€“max(100, T/3) (**10**) | Ignore early window in metric calculations       |

### âš™ï¸ Advanced

| UI Control                  | Range (default)   | Notes                                             |
| --------------------------- | ----------------- | ------------------------------------------------- |
| **Random Seed**             | 1â€“999999 (**42**) | Reproducibility                                   |
| **Show Parameter Warnings** | toggle (On)       | Validation hints (e.g., sensitivity too low/high) |

---

## ğŸ“Š Metrics (what the app reports)

From `calculate_learning_metrics`:

* **learning\_score**: Normalized cooling from initial temp toward 30Â°C (0â€“1).
* **final\_gfp**: Driverâ€™s mean GFP at the end.
* **final\_temperature**: Driverâ€™s last temperature.
* **adaptation\_time**: First time (after burn-in) that temperature crosses halfway between initial and final.
* **establishment\_time**: First time (after burn-in) high-GFP fraction â‰¥ 0.5.
* **temperature\_stability**: 1 / (1 + variance) over the last 20% of temps.
* **final\_high\_gfp\_fraction**: Fraction of cells above threshold (binary: >50; continuous: >60).

**Quick interpretation**

* **Learning Score > 0.7** â†’ strong adaptation
* **0.3â€“0.7** â†’ moderate
* **< 0.3** â†’ weak

--- 

## ğŸ“ How Metrics Are Calculated

Metrics are computed in `calculate_learning_metrics` (see `src/main.py`) and summarize the driver wellâ€™s adaptation. Here is how each key variable is derived:

* **`learning_score`**
  Measures how much the driver cooled relative to its starting temperature.

  $$
  \text{learning\_score} = \frac{\text{initial\_temp} - \text{final\_temp}}{\max(\text{initial\_temp} - 30.0,\; 1\text{e-9})}
  $$

  Normalized between **0 (no cooling)** and **1 (full cooling to 30Â°C)**.

* **`final_gfp`**
  The driverâ€™s **mean GFP value at the last time step**.

* **`final_temperature`**
  The driverâ€™s **last recorded temperature** in the simulation.

* **`adaptation_time`**
  The **first time (after burn-in)** that the driverâ€™s temperature drops below the halfway point between its initial and final temperature:

  $$
  T_{\text{mid}} = \text{initial\_temp} - 0.5 \times (\text{initial\_temp} - \text{final\_temp})
  $$

  The earliest time where $T(t) \leq T_{\text{mid}}$ is reported.

* **`establishment_time`**
  The **first time (after burn-in)** that the driverâ€™s high-GFP fraction reaches or exceeds 0.5 (â‰¥50% of cells above threshold).

* **`temperature_stability`**
  Computed as:

  $$
  \text{temperature\_stability} = \frac{1}{1 + \mathrm{Var}(T_{\text{last 20\%}})}
  $$

  A value closer to **1** indicates more stable temperatures in the final phase.

* **`final_high_gfp_fraction`**
  The **fraction of driver cells** at the last time step with GFP above threshold:

  * continuous mode â†’ GFP > 60
  * binary mode â†’ GFP > 50.


---

## ğŸ§ª Recommended Protocols

### ğŸŸ¢ Basic Learning (Beginner)

* **Mode:** continuous
* **Time:** 1000 min, **Pop:** 200, **Passives:** 3
* **Feedback:** linear, **Sensitivity:** 1.0
* **Evolution:** noise 5.0, switch 0.01, cost 0.3, curvature 1.5
  **Expect:** Cooling into low 30s Â°C, learning\_score â‰³ 0.6

### ğŸŸ¡ Binary Switching (Intermediate)

* **Mode:** binary
* **Time:** 800 min, **Pop:** 300, **Passives:** 4
* **Feedback:** step, **Sensitivity:** 1.5
* **Evolution:** (inheritance noise not crucial), switch 0.02, cost 0.4, curvature 1.0
  **Expect:** Rapid transition, learning\_score â‰³ 0.7

### ğŸ”´ Challenging Conditions (Advanced)

* **Mode:** continuous
* **Time:** 1500 min, **Pop:** 500, **Passives:** 5
* **Feedback:** sigmoid, **Sensitivity:** 0.6
* **Evolution:** noise 8.0, switch 0.008, cost 0.5, curvature 2.0
  **Expect:** Slower adaptation, learning\_score â‰ˆ 0.3â€“0.6

### ğŸ”µ Failure Mode Analysis

* **Mode:** continuous
* **Time:** 1000 min, **Pop:** 150, **Passives:** 3
* **Feedback:** linear, **Sensitivity:** 0.3
* **Evolution:** noise 15.0, switch 0.003, cost 0.8, curvature 2.5
  **Expect:** Likely failure (score < 0.3). Great for sensitivity analysis.

### âš¡ Rapid Learning (Expert)

* **Mode:** binary
* **Time:** 500 min, **Pop:** 400, **Passives:** 3
* **Feedback:** exponential, **Sensitivity:** 2.0
* **Evolution:** noise 1.0, switch 0.04, cost 0.2, curvature 1.0
  **Expect:** Very fast adaptation (score > 0.8), short adaptation\_time.

---

## ğŸ“¥ Data Export

* **CSV (Time Series):** driver/passives/controls GFP, driver temp, control temps (for constant-temp verification), high-GFP fractions, population size.
* **JSON (Parameters & Metrics):** full simulation and GFP params + summary metrics.
* **JSON (Raw):** complete per-well histories and final distributions.

---

## ğŸ” Troubleshooting & Validation

The app warns when parameters are likely problematic:

* **Very low sensitivity** â†’ â€œmay prevent learningâ€
* **Very high sensitivity** â†’ â€œmay cause instabilityâ€
* **High GFP cost or switching** â†’ noise/slow growth
* **Small populations or short runs** â†’ drift/under-adaptation
* **temp\_inertia outside (0,1]** â†’ invalid

**Remember:** Only the **driver** uses feedback + inertia. **Controls** are **always 30Â°C** and **39Â°C**; **passives** simply **follow the driver temperature** with no influence.

---

## ğŸ”¬ Tips for Study Design

* Compare **binary vs. continuous** under the same settings.
* Sweep **sensitivity** (0.2, 0.5, 1.0, 1.5, 2.0, 4.0).
* Vary **population size** (100â€“800) for drift effects.
* Run **replicates** with different **random\_seed** values and aggregate.
* Use **metric\_burn\_in** (e.g., 10â€“100 min) to avoid startup artefacts.

---

## ğŸ§ª CLI Smoke Test (optional)

The core module includes a simple test in `src/main.py`:

```bash
python -m src.main
```

It runs a short binary-mode simulation and prints key metrics.

---

## ğŸ“œ License & Citation

* Choose an open-source license appropriate for your project.
* If you use this in a publication, please cite the repository and include the **strict Moran** and **fixed-controls** details.

---

**Happy experimenting!** If you have questions or want to collaborate, open an issue or reach out.
*Last Updated: 2025 â€¢ Status: Active*

---

## ğŸ§¾ Results interpretation: current behavior vs. reality

### Your observed outcomes (from the app)
- The 39â€¯Â°C control reaches and maintains the highest GFP.
- The feedback â€œdriverâ€ well looks similar to the â€œpassiveâ€ wells (they experience the same temperature trajectory; passives donâ€™t influence it).
- The 30â€¯Â°C control remains lowest GFP.

### Why the current model produces this
This app uses a strict Moran process (exactly 1 birth + 1 death per step; population fixed). Fitness is inversely related to generation time, and heat increases switching toward high-GFP states. Under these assumptions:
- At constant 39â€¯Â°C, stress increases switching since we defined a stress-induced high switching rate. If we drop that to zero - all wells get to a very low gfp level.
- The driver and passives share the same temperature each step; passives simply track the driverâ€™s environment without feeding back, plus they are doing the exact same moran process â€” so their trajectories can be very similar.
- At constant 30â€¯Â°C, thereâ€™s minimal switching of GFP levels, and the generation time is minimal, so GFP stays low.

### Why experiments can differ
Real systems often deviate from strict Moran assumptions and include biophysical effects not modeled here:
- Non-Moran updates: multiple deaths without births (and vice versa), variable population size, batch effects, and asynchronous events.
- Global expression dampening under chronic stress: transcription/translation burdens reduce overall protein levels.
- Heat-accelerated GFP degradation/maturation changes: faster decay or slower proper folding at high temperature can lower steady-state GFP despite selection.
- Additional resource and damage constraints: sustained stress can accumulate damage, lower fitness broadly, or reprioritize expression away from GFP.

### Suggestions for model extensions to better match reality
If we want the 39â€¯Â°C control to rise then drop (more realistic), we can try these tweaks in the engine:
- Relax strict Moran: decouple birth/death events (allow k deaths without births), or use stochastic rates (e.g., Gillespie-style events) with temperature-dependent death rates.
- Add explicit GFP dynamics: dGFP/dt = production âˆ’ decay with temperature-dependent decay (and optional maturation delay); reduce production globally under stress.
- Temperature-dependent global cost: scale the cost multiplier up with temperature to reflect broad expression slow-downs.
- Damage/aging state: accumulate stress-induced damage that reduces division rate or increases death probability over time at high temperatures.
- Resource limits: impose carrying-capacity or energy budget constraints that penalize sustained high GFP under stress.



--- 
# Batch Summary: Recommended Protocols

This report aggregates metrics and links to plots generated by scripts/run_protocols.py.

## basic_learning

**Key metrics**:

- learning_score: 0.57
- final_gfp: 56.8
- final_temperature: 33.9 Â°C
- adaptation_time: 167.0
- final_high_gfp_fraction: 0.47

**Interpretation**:

> Learning score: 0.57; Final temp: 33.9Â°C; Final driver GFP: 56.8
> Driver cooled substantially; indicates good feedback-driven adaptation.
> 39Â°C control > 30Â°C control, consistent with heat-induced switching/selection.

![Temperature basic_learning](Results_Export_dir/temp_basic_learning.png)

![GFP basic_learning](Results_Export_dir/gfp_basic_learning.png)

---

## binary_switching

**Key metrics**:

- learning_score: 1.00
- final_gfp: 40.4
- final_temperature: 30.0 Â°C
- adaptation_time: 10.0
- final_high_gfp_fraction: 0.09

**Interpretation**:

> Learning score: 1.00; Final temp: 30.0Â°C; Final driver GFP: 40.4
> Driver cooled substantially; indicates good feedback-driven adaptation.
> 39Â°C control > 30Â°C control, consistent with heat-induced switching/selection.

![Temperature binary_switching](Results_Export_dir/temp_binary_switching.png)

![GFP binary_switching](Results_Export_dir/gfp_binary_switching.png)

---

## challenging

**Key metrics**:

- learning_score: 0.31
- final_gfp: 70.4
- final_temperature: 36.2 Â°C
- adaptation_time: 544.0
- final_high_gfp_fraction: 0.70

**Interpretation**:

> Learning score: 0.31; Final temp: 36.2Â°C; Final driver GFP: 70.4
> Moderate cooling; parameters allow some adaptation but not strong.
> 39Â°C control > 30Â°C control, consistent with heat-induced switching/selection.

![Temperature challenging](Results_Export_dir/temp_challenging.png)

![GFP challenging](Results_Export_dir/gfp_challenging.png)

---

## failure_mode

**Key metrics**:

- learning_score: 0.11
- final_gfp: 36.7
- final_temperature: 38.0 Â°C
- adaptation_time: 161.0
- final_high_gfp_fraction: 0.18

**Interpretation**:

> Learning score: 0.11; Final temp: 38.0Â°C; Final driver GFP: 36.7
> Weak/no cooling; likely low sensitivity or high cost/noise.
> 39Â°C control > 30Â°C control, consistent with heat-induced switching/selection.

![Temperature failure_mode](Results_Export_dir/temp_failure_mode.png)

![GFP failure_mode](Results_Export_dir/gfp_failure_mode.png)

---

## rapid_learning

**Key metrics**:

- learning_score: 0.95
- final_gfp: 62.5
- final_temperature: 30.4 Â°C
- adaptation_time: 10.0
- final_high_gfp_fraction: 0.46

**Interpretation**:

> Learning score: 0.95; Final temp: 30.4Â°C; Final driver GFP: 62.5
> Driver cooled substantially; indicates good feedback-driven adaptation.
> 39Â°C control > 30Â°C control, consistent with heat-induced switching/selection.

![Temperature rapid_learning](Results_Export_dir/temp_rapid_learning.png)

![GFP rapid_learning](Results_Export_dir/gfp_rapid_learning.png)

---
